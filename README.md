
# ğŸ§  AI-Powered Code & Developer Agent

A local GenAI-powered code assistant that helps you **explain, debug, and optimize Python code** â€” with or without LLMs. Built using Mistral-7B (GGUF), LangChain, and Streamlit, it runs entirely offline with two modes:

### ğŸš€ Key Features

- **Explain Mode** â€“ Understand logic line-by-line
- **Fix Mode** â€“ Auto-debug code errors and improve logic
- **Optimize Mode** â€“ Refactor for better performance/readability
- **Chat Mode** â€“ Multi-turn AI tutor with memory
- **File Upload + Markdown Export**
- **Runs 100% Locally â€“ No API, No Cloud**

---

### ğŸ› ï¸ Tech Stack

- `Mistral-7B` (GGUF - Q4_K_M)
- `LangChain` + `ConversationBufferMemory`
- `GPT4All` local LLM runtime
- `Streamlit` UI
- Python core tools (`ast`, `tempfile`, `os`, etc.)

---

### ğŸ“‚ Dual Modes

| Mode | File | Description |
|------|------|-------------|
| `app.py` | ğŸ”§ Static App | Rule-based, no LLMs, fast code analysis |
| `ai_code_assistant_app.py` | ğŸ§  Agentic App | LLM-based with Mistral-7B, chat-style memory |

---

### ğŸ“¦ Folder Structure
AI_Code_Developer_Assistant/
â”œâ”€â”€ requirements.txt

â”œâ”€â”€ models/
â”‚   â””â”€â”€ mistral-7b-openorca.Q4_K_M.gguf

â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ example_buggy_code.py
â”‚   â”œâ”€â”€ example_insecure_code.py
â”‚   â””â”€â”€ example_unoptimized_code.py

â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ example_buggy_code_analysis.csv
â”‚   â”œâ”€â”€ example_buggy_code_debug_report.txt
â”‚   â”œâ”€â”€ example_insecure_code_analysis.csv
â”‚   â”œâ”€â”€ example_unoptimized_code_analysis.csv
â”‚   â”œâ”€â”€ example_unoptimized_code_optimized.py
â”‚   â”œâ”€â”€ inline_opt_temp_optimized.py
â”‚   â”œâ”€â”€ inline_struct_temp_analysis.csv
â”‚   â”œâ”€â”€ tmp6gnz615m_debug_report.txt
â”‚   â”œâ”€â”€ tmp331y4se3_debug_report.txt
â”‚   â”œâ”€â”€ tmpi9p_hsnn_debug_report.txt
â”‚   â””â”€â”€ tmpxkdqb3ti_debug_report.txt

â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ ai_code_assistant_app.py
â”‚   â”œâ”€â”€ auto_debugger.py
â”‚   â”œâ”€â”€ code_analysis.py
â”‚   â”œâ”€â”€ code_optimizer.py
â”‚   â”œâ”€â”€ llm_agent.py
â”‚   â””â”€â”€ prompt_templates.py

â””â”€â”€ README.md



### âš™ï¸ How to Run

1. Clone this repo and create a virtual environment.
2. Download Mistral model (`mistral-7b-openorca.Q4_K_M.gguf`) and place it in `/models`.
3. Install dependencies:
   ```bash
   pip install -r requirements.txt


Run either app:
Static: streamlit run app.py
Agent: streamlit run ai_code_assistant_app.py



Project Highlights
Local-first AI â€” ideal for secure or educational environments.
No OpenAI or paid API required.
Designed for learners, freelancers, educators, and AI engineers.
Modular â€” extendable to other languages or multi-agent systems.


Conceptual Study
Read the full deep-dive behind this project: Conceptual Study â†’

 Author
Prerna Burande
AI | Strategy | Portfolio Engineering


ğŸ“„ License
MIT â€” for personal/educational use only. Contact for commercial licensing.

---

